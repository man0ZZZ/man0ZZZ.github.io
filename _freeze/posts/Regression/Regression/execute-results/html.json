{
  "hash": "00bb97942eae366c92c0f19a265a4a22",
  "result": {
    "markdown": "---\ntitle: 'Regression: tweaking model parameter'\nauthor: Manoj Subedi\ndate: now\ncategories:\n  - code\n  - regression\nformat:\n  html:\n    mermaid:\n      theme: default\n    output-file: index.html\n---\n\n# Introduction\n\nWelcome to a hands-on exploration of solving a regression problem using polynomial regression. In this scenario, we're dealing with a classic machine learning problem -- predicting salaries based on job levels. The dataset includes information about hypothetical job positions and corresponding salaries.\n\nProblem Statement: The goal here is to build a regression model that accurately predicts salaries. Initially, we attempt a simple linear regression model. However, if the relationship between job levels and salaries is more complex than a straight line, we need a model that can capture these nuances.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n::: {.cell execution_count=2}\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Position</th>\n      <th>Level</th>\n      <th>Salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Business Analyst</td>\n      <td>1</td>\n      <td>45000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Junior Consultant</td>\n      <td>2</td>\n      <td>50000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Senior Consultant</td>\n      <td>3</td>\n      <td>60000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Manager</td>\n      <td>4</td>\n      <td>80000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Country Manager</td>\n      <td>5</td>\n      <td>110000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Region Manager</td>\n      <td>6</td>\n      <td>150000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Partner</td>\n      <td>7</td>\n      <td>200000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Senior Partner</td>\n      <td>8</td>\n      <td>300000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>C-level</td>\n      <td>9</td>\n      <td>500000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>CEO</td>\n      <td>10</td>\n      <td>1000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n# Exploratory Data Analysis:\n\nBefore diving into modeling, it's crucial to understand the data. The scatter plot visualizes the relationship between job levels and salaries, offering insights into the potential complexity of the underlying patterns.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nplt.scatter(df['Level'], df['Salary'])\nplt.xlabel(\"Level\")\nplt.ylabel(\"Salary\")\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\nText(0, 0.5, 'Salary')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Regression_files/figure-html/cell-4-output-2.png){width=589 height=443}\n:::\n:::\n\n\n# Linear Regression:\n\nTo start, we apply a simple linear regression model, assuming a linear relationship between job levels and salaries. The model aims to minimize the difference between actual and predicted salaries.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n#fit linear regression\nfrom sklearn.linear_model import LinearRegression\ny=df.iloc[:,-1].values\nX=df.iloc[:,-2:-1].values\nlin_reg=LinearRegression()\nlin_reg.fit(X,y)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\n# Model evaluation:\n\nWe evaluate the performance of the linear regression model using the R-squared metric. A low R-squared value may suggest that a linear model is insufficient for capturing the relationship in the data.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ny_pred = lin_reg.predict(X)\n\ndef r2(y, y_pred):\n  tss=0\n  rss=0\n  mean_true = sum(y) / len(y)\n  for true, pred in zip(y, y_pred):\n    tss+=(true-mean_true)**2\n    rss+=(true-pred)**2\n  return 1 - (rss / tss)\n\nr_sq = r2(y, y_pred)\nplt.scatter(df.Level, df.Salary, color='black')\nplt.plot(X, lin_reg.predict(X), color='black')\nplt.text(8.5, 0.75, rf'R$^2$: {r_sq:.2f}', fontsize=10, verticalalignment='top')\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\nText(8.5, 0.75, 'R$^2$: 0.67')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Regression_files/figure-html/cell-6-output-2.png){width=571 height=425}\n:::\n:::\n\n\n# Polynomial Regression and model evaluation:\n\nRecognizing potential non-linearity, we explore polynomial regression. By transforming our feature variable with different degrees, we can model curved relationships beyond what linear regression allows. We evaluate each polynomial regression model, emphasizing the importance of selecting the right degree for the polynomial features. This process allows us to uncover more complex relationships in the data.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import PolynomialFeatures\n\nfig, axs = plt.subplots(3, 1, figsize=(8, 12))\n\n# polynomial regression plots with different degrees\nfor degree, ax in zip([2, 3, 4], axs):\n    # Polynomial features\n    poly_feat = PolynomialFeatures(degree=degree)\n    X_poly = poly_feat.fit_transform(X)\n    \n    # Linear regression\n    linreg_for_polyreg = LinearRegression()\n    linreg_for_polyreg.fit(X_poly, y)\n    \n    # Predicted y values\n    y_poly_pred = linreg_for_polyreg.predict(X_poly)\n    \n    # Plot\n    ax.scatter(X, y, color='black')\n    ax.plot(X, y_poly_pred, color='black')\n    r_sq=r2(y, y_poly_pred)\n    ax.set_title(f'Degree {degree} Polynomial Regression')\n    ax.text(8.5, 0.2e6, rf'R$^2$: {r_sq:.2f}', fontsize=10, verticalalignment='top')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Regression_files/figure-html/cell-7-output-1.png){width=758 height=1141}\n:::\n:::\n\n\n# Predictions and Plotting:\n\nTo conclude, we compare predictions from both linear and polynomial regression models. This not only demonstrates the flexibility of polynomial regression but also highlights the importance of selecting the appropriate model for a given problem.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nx_test=[1.5, 7.8]\n\n#plotting the predicted points\nplt.scatter(X, y, label='Actual Data', color='black')\nplt.scatter(x_test, lin_reg.predict([[1.5], [7.8]]), label='Linear Regression Predictions', marker='x', color='red')\nplt.scatter(x_test, linreg_for_polyreg.predict(poly_feat.fit_transform([[1.5],[7.8]])), label='Polynomial Regression Predictions', marker='o', color='blue')\n\nplt.title('Linear and Polynomial Regression Predictions')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Regression_files/figure-html/cell-8-output-1.png){width=589 height=449}\n:::\n:::\n\n\n",
    "supporting": [
      "Regression_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}